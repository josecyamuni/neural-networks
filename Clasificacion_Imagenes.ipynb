{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6ff0a1d",
   "metadata": {},
   "source": [
    "Alejandra Velasco Zárate A01635453\n",
    "\n",
    "José Antonio Juárez Pacheco A0057218\n",
    "\n",
    "José Carlos Yamuni Contreras A01740285\n",
    "\n",
    "Juan Manuel Hernández Solano A00572208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6f84ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alejandra Velasco\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n",
      "C:\\Users\\Alejandra Velasco\\AppData\\Local\\Temp\\ipykernel_19744\\3351578344.py:23: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import load_img\n",
    "import os\n",
    "from skimage import io, feature\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray, rgb2lab\n",
    "from skimage import img_as_ubyte\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from prettytable import PrettyTable\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a4c9c",
   "metadata": {},
   "source": [
    "# Calsificador de imágenes Fashion-MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d0a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar conjunto de datos de fashion\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bbdc8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de imágenes\n",
    "x_train = x_train.reshape((x_train.shape[0], -1)) / 255.0\n",
    "x_test = x_test.reshape((x_test.shape[0], -1)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32917608",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train[:20000], y_train[:20000]\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e98988",
   "metadata": {},
   "source": [
    "## Support Vector Machine base lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e801f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo: 0.8145\n",
      "Sensibilidad (Recall) por clase:\n",
      "Clase 0: 0.8000\n",
      "Clase 1: 0.9640\n",
      "Clase 2: 0.7200\n",
      "Clase 3: 0.8010\n",
      "Clase 4: 0.6870\n",
      "Clase 5: 0.9240\n",
      "Clase 6: 0.5000\n",
      "Clase 7: 0.8990\n",
      "Clase 8: 0.9280\n",
      "Clase 9: 0.9220\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo SVM lineal\n",
    "model = make_pipeline(StandardScaler(), SVC(kernel='linear'))\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall_per_class = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "print(f'Exactitud del modelo: {accuracy:.4f}')\n",
    "print('Sensibilidad (Recall) por clase:')\n",
    "for i, recall in enumerate(recall_per_class):\n",
    "    print(f'Clase {i}: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef80750",
   "metadata": {},
   "source": [
    "## Support Vector Machine base radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb3b73df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), SVC(kernel='rbf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dc570df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo: 0.8628\n",
      "Sensibilidad (Recall) por clase:\n",
      "Clase 0: 0.8060\n",
      "Clase 1: 0.9530\n",
      "Clase 2: 0.7880\n",
      "Clase 3: 0.8910\n",
      "Clase 4: 0.7910\n",
      "Clase 5: 0.9370\n",
      "Clase 6: 0.6230\n",
      "Clase 7: 0.9290\n",
      "Clase 8: 0.9670\n",
      "Clase 9: 0.9430\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall_per_class = recall_score(y_test, y_pred, average=None)\n",
    "\n",
    "print(f'Exactitud del modelo: {accuracy:.4f}')\n",
    "print('Sensibilidad (Recall) por clase:')\n",
    "for i, recall in enumerate(recall_per_class):\n",
    "    print(f'Clase {i}: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7bb9b5",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa\n",
    "### Red Neuronal con cross validation y hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65ee0395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c37eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01a1b500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap = 'binary')\n",
    "plt.xlabel(y_train[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc98a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    \n",
    "    num_hidden_layers = 1\n",
    "    num_units = 8\n",
    "    dropout_rate = 0.1\n",
    "    learning_rate = 0.001\n",
    "    \n",
    "    if hp:\n",
    "        num_hidden_layers = hp.Choice('num_hidden_layers', values=[2, 3, 4])\n",
    "        num_units = hp.Choice('num_units', values=[16, 32, 64])\n",
    "    \n",
    "    model=tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Flatten(input_shape = (28, 28)))\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: x/255.))\n",
    "    \n",
    "    for _ in range(0, num_hidden_layers):\n",
    "        model.add(tf.keras.layers.Dense(num_units, activation = 'relu'))\n",
    "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss = 'sparse_categorical_crossentropy', \n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
    "        metrics =['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d2aedc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 8)                 6280      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6370 (24.88 KB)\n",
      "Trainable params: 6370 (24.88 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_model(None).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4aa557b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridtuner = keras_tuner.GridSearch(\n",
    "    create_model,\n",
    "    objective='val_accuracy',\n",
    "    directory = 'grid_search',\n",
    "    project_name = 'fashionmnist_mlp', \n",
    "    overwrite = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a20509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 2\n",
      "num_hidden_layers (Choice)\n",
      "{'default': 2, 'conditions': [], 'values': [2, 3, 4], 'ordered': True}\n",
      "num_units (Choice)\n",
      "{'default': 16, 'conditions': [], 'values': [16, 32, 64], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "gridtuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b00555",
   "metadata": {},
   "outputs": [],
   "source": [
    "gridtuner.search(x_train, y_train, validation_data=(x_test, y_test), epochs = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a826d874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in grid_search\\fashionmnist_mlp\n",
      "Showing 3 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0002 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 2\n",
      "num_units: 64\n",
      "Score: 0.8738999962806702\n",
      "\n",
      "Trial 0005 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 3\n",
      "num_units: 64\n",
      "Score: 0.8668000102043152\n",
      "\n",
      "Trial 0008 summary\n",
      "Hyperparameters:\n",
      "num_hidden_layers: 4\n",
      "num_units: 64\n",
      "Score: 0.8618999719619751\n"
     ]
    }
   ],
   "source": [
    "gridtuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25ba0592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55050 (215.04 KB)\n",
      "Trainable params: 55050 (215.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = gridtuner.get_best_models(num_models = 1)[0]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "844df7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c888c0d990>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 20, batch_size = 128, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a55571f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 873us/step\n",
      "Accuracy: 0.8849\n",
      "Recall para la clase T-shirt/top: 0.879\n",
      "Recall para la clase Trouser: 0.976\n",
      "Recall para la clase Pullover: 0.818\n",
      "Recall para la clase Dress: 0.875\n",
      "Recall para la clase Coat: 0.783\n",
      "Recall para la clase Sandal: 0.965\n",
      "Recall para la clase Shirt: 0.667\n",
      "Recall para la clase Sneaker: 0.97\n",
      "Recall para la clase Bag: 0.972\n",
      "Recall para la clase Ankle boot: 0.944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "class_names = {\n",
    "    0: 'T-shirt/top',\n",
    "    1: 'Trouser',\n",
    "    2: 'Pullover',\n",
    "    3: 'Dress',\n",
    "    4: 'Coat',\n",
    "    5: 'Sandal',\n",
    "    6: 'Shirt',\n",
    "    7: 'Sneaker',\n",
    "    8: 'Bag',\n",
    "    9: 'Ankle boot'\n",
    "}\n",
    "\n",
    "labels = list(class_names.keys())\n",
    "recall_per_class = recall_score(y_test, y_pred_classes, labels=labels, average=None)\n",
    "\n",
    "for label, recall in zip(labels, recall_per_class):\n",
    "    class_name = class_names[label]\n",
    "    print(f'Recall para la clase {class_name}: {recall}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d1466f",
   "metadata": {},
   "source": [
    "El clasificador con peor exactitud fue el de Support Vector Machine de base lineal, una exactitud de $0.81$, lo cual no es malo pero podría mejorar. Support vector machine de base radial con una exactitud de $0.86$. Se puede observar que un clasificador que no sea lineal clasifica mejor que uno lineal. Finalmente, se concluye que el mejor clasificador para imágenes de fashion es la red perceptrón multicapa, ya que tuvo una exactitud de $0.88$. Además de que en la mayoría de las clases la sensibilidad fue mejor en el modelo perceptron. Con este ejemplo, se puede argumentar y validar que las redes neuronales son los mejores clasificadores al momento de hablar de datos no estructurados como lo son"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2c8ad",
   "metadata": {},
   "source": [
    "# Clasificador de imágenes satelitales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25968f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de características: (2016, 52)\n",
      "Dimensiones de etiquetas: (2016,)\n"
     ]
    }
   ],
   "source": [
    "# Establecer el ancho y altura de las imágenes después del redimensionamiento\n",
    "img_width, img_height = 128, 128\n",
    "\n",
    "# Directorio raíz donde se encuentran las carpetas de clases\n",
    "root_dir = \"data\"\n",
    "\n",
    "# Lista de subdirectorios (cada subdirectorio es una clase)\n",
    "class_folders = [folder for folder in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, folder))]\n",
    "\n",
    "# Listas para almacenar características y etiquetas\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Función para extraer características de una imagen\n",
    "def extract_features(image):\n",
    "    # Redimensionar la imagen a 128x128\n",
    "    rgb_resized = resize(image, (img_height, img_width), anti_aliasing=True)\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray_resized = img_as_ubyte(rgb2gray(rgb_resized))\n",
    "\n",
    "    # Histogramas de color\n",
    "    nbins = 16\n",
    "    rh = np.histogram(rgb_resized[:,:,0].flatten(), nbins, density=True)\n",
    "    gh = np.histogram(rgb_resized[:,:,1].flatten(), nbins, density=True)\n",
    "    bh = np.histogram(rgb_resized[:,:,2].flatten(), nbins, density=True)\n",
    "    hist_descriptor = np.concatenate((rh[0], gh[0], bh[0]))\n",
    "\n",
    "    # Descriptores de textura usando GLCM\n",
    "    glcm = graycomatrix(gray_resized, distances=[5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    texture_desc = [graycoprops(glcm, 'dissimilarity')[0, 0], graycoprops(glcm, 'homogeneity')[0, 0], graycoprops(glcm, 'energy')[0, 0], graycoprops(glcm, 'correlation')[0, 0]]\n",
    "\n",
    "    return hist_descriptor, texture_desc\n",
    "\n",
    "# Iterar sobre cada carpeta de clase\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(root_dir, class_folder)\n",
    "\n",
    "    # Iterar sobre cada archivo de imagen en la carpeta de clase\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):  # Asegurarse de que el archivo sea una imagen\n",
    "            image_path = os.path.join(class_path, filename)\n",
    "\n",
    "            # Cargar la imagen\n",
    "            rgb = io.imread(image_path)\n",
    "\n",
    "            # Extraer características\n",
    "            hist_descriptor, texture_desc = extract_features(rgb)\n",
    "\n",
    "            # Almacenar características y etiquetas\n",
    "            all_features.append(np.concatenate([hist_descriptor, texture_desc]))\n",
    "            all_labels.append(class_folder)\n",
    "\n",
    "# Convertir a matrices numpy\n",
    "all_features = np.array(all_features)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Verificar las dimensiones de las matrices resultantes\n",
    "print(\"Dimensiones de características:\", all_features.shape)\n",
    "print(\"Dimensiones de etiquetas:\", all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a966ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.36250858e+00, 7.03765372e+00, 6.68000013e+00, 4.16502568e+00,\n",
       "       2.08465021e+00, 4.17500008e-01, 2.82133111e-01, 1.52465873e-01,\n",
       "       6.12713322e-02, 5.69965881e-02, 1.42491470e-02, 9.97440292e-03,\n",
       "       8.54948822e-03, 1.42491470e-03, 4.27474411e-03, 7.12457351e-03,\n",
       "       1.97112361e+00, 6.93053957e+00, 6.62452694e+00, 4.17067918e+00,\n",
       "       2.48976473e+00, 6.16335298e-01, 3.37619569e-01, 2.14065173e-01,\n",
       "       1.06314247e-01, 3.01702593e-02, 1.58034692e-02, 8.62007409e-03,\n",
       "       5.74671606e-03, 5.74671606e-03, 2.87335803e-03, 8.62007409e-03,\n",
       "       1.31359762e+00, 6.28989671e+00, 8.66415454e+00, 4.92459365e+00,\n",
       "       1.05087810e+00, 3.43771293e-01, 2.04026865e-01, 3.91284399e-02,\n",
       "       1.95642199e-02, 1.39744428e-02, 9.78210997e-03, 5.58977712e-03,\n",
       "       5.58977712e-03, 0.00000000e+00, 5.58977712e-03, 5.58977712e-03,\n",
       "       4.76460874e+00, 2.47433665e-01, 4.24899570e-02, 8.53668553e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53056506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agua'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b248b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar las características\n",
    "all_features_standard = (all_features - all_features.min()) / (all_features.max() - all_features.min())\n",
    "\n",
    "# Codificar etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "# Codificar etiquetas en formato one-hot\n",
    "all_labels_onehot = to_categorical(all_labels_encoded, num_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456bdd97",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b9363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_cross_validation(x,y,n,tipo,a, c):\n",
    "    n_folds = n\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle = True)\n",
    "\n",
    "    acc = 0\n",
    "    recall = np.array([0., 0., 0.])\n",
    "    precision = np.array([0., 0., 0.])\n",
    "\n",
    "    cv_y_test = []\n",
    "    cv_y_pred = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(x, y):\n",
    "        # Training phase\n",
    "        x_train = x[train_index, :]\n",
    "        y_train = y[train_index]\n",
    "        \n",
    "        clf_cv = SVC(C = c, kernel = tipo)\n",
    "        clf_cv.fit(x_train, y_train)\n",
    "        # Test phase\n",
    "        x_test = x[test_index, :]\n",
    "        y_test = y[test_index]\n",
    "        y_pred = clf_cv.predict(x_test)\n",
    "        \n",
    "        # Concatenate results of evaluation\n",
    "        cv_y_test.append(y_test)\n",
    "        cv_y_pred.append(y_pred)\n",
    "        \n",
    "        # Model performance\n",
    "        if a == True:\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Model performance\n",
    "    print(\"Resultados del clasificador:\\n\\n\")\n",
    "    # Crea la tabla\n",
    "    report = classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred), output_dict=True)\n",
    "    accuracy = report['accuracy']\n",
    "    table = PrettyTable()\n",
    "    table.field_names = ['Clase', 'Precisión', 'Recall', 'Puntaje F1', 'Soporte']\n",
    "\n",
    "    # Agrega las filas a la tabla\n",
    "    for class_label, metrics in report.items():\n",
    "        if class_label != 'accuracy':\n",
    "            precision = metrics['precision']\n",
    "            recall = metrics['recall']\n",
    "            f1_score = metrics['f1-score']\n",
    "            support = metrics['support']\n",
    "            table.add_row([class_label, precision, recall, f1_score, support])\n",
    "\n",
    "    # Imprime el resultado\n",
    "    print(table)\n",
    "    print(\"\\nAccuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98503757",
   "metadata": {},
   "source": [
    "### Support vector machine lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00cc066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.75      0.79        67\n",
      "           1       0.69      0.79      0.74        67\n",
      "           2       0.57      0.96      0.71        68\n",
      "           3       0.76      0.38      0.51        66\n",
      "           4       0.83      0.81      0.82        67\n",
      "           5       0.47      0.38      0.42        69\n",
      "\n",
      "    accuracy                           0.68       404\n",
      "   macro avg       0.69      0.68      0.66       404\n",
      "weighted avg       0.69      0.68      0.66       404\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86        67\n",
      "           1       0.74      0.82      0.78        67\n",
      "           2       0.48      0.87      0.62        67\n",
      "           3       0.82      0.21      0.33        67\n",
      "           4       0.75      0.93      0.83        67\n",
      "           5       0.42      0.31      0.36        68\n",
      "\n",
      "    accuracy                           0.66       403\n",
      "   macro avg       0.69      0.66      0.63       403\n",
      "weighted avg       0.69      0.66      0.63       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.76      0.82        67\n",
      "           1       0.72      0.72      0.72        67\n",
      "           2       0.48      0.79      0.60        67\n",
      "           3       0.84      0.31      0.46        67\n",
      "           4       0.70      0.87      0.77        67\n",
      "           5       0.52      0.46      0.48        68\n",
      "\n",
      "    accuracy                           0.65       403\n",
      "   macro avg       0.69      0.65      0.64       403\n",
      "weighted avg       0.69      0.65      0.64       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        67\n",
      "           1       0.81      0.75      0.78        67\n",
      "           2       0.50      0.84      0.63        67\n",
      "           3       0.73      0.16      0.27        67\n",
      "           4       0.74      0.94      0.83        67\n",
      "           5       0.49      0.47      0.48        68\n",
      "\n",
      "    accuracy                           0.66       403\n",
      "   macro avg       0.69      0.66      0.64       403\n",
      "weighted avg       0.69      0.66      0.64       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.72      0.77        67\n",
      "           1       0.64      0.75      0.69        67\n",
      "           2       0.49      0.84      0.62        67\n",
      "           3       0.80      0.18      0.29        67\n",
      "           4       0.81      0.88      0.84        66\n",
      "           5       0.48      0.45      0.46        69\n",
      "\n",
      "    accuracy                           0.63       403\n",
      "   macro avg       0.67      0.63      0.61       403\n",
      "weighted avg       0.67      0.63      0.61       403\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "|    Clase     |      Precisión      |        Recall       |      Puntaje F1     | Soporte |\n",
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "|      0       |  0.8686868686868687 |  0.7701492537313432 |  0.8164556962025317 |  335.0  |\n",
      "|      1       |  0.7150837988826816 |  0.764179104477612  |  0.7388167388167388 |  335.0  |\n",
      "|      2       |  0.5026178010471204 |  0.8571428571428571 |  0.6336633663366337 |  336.0  |\n",
      "|      3       |  0.7904761904761904 | 0.24850299401197604 | 0.37813211845102507 |  334.0  |\n",
      "|      4       |  0.7603092783505154 |  0.8832335329341318 |  0.8171745152354571 |  334.0  |\n",
      "|      5       | 0.47796610169491527 | 0.41228070175438597 |  0.4427001569858713 |  342.0  |\n",
      "|  macro avg   |  0.6858566731897153 |  0.6559147406753844 |  0.6378237653380429 |  2016.0 |\n",
      "| weighted avg |  0.6849551131723277 |  0.6552579365079365 |  0.6371840407544729 |  2016.0 |\n",
      "+--------------+---------------------+---------------------+---------------------+---------+\n",
      "\n",
      "Accuracy =  0.6552579365079365\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(all_features_standard,all_labels_encoded,5,\"linear\",True, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98f675",
   "metadata": {},
   "source": [
    "El clasificador de SVM Lineal tiene una exactitud de $0.655$, lo cual es un valor inaceptable al referirse a un clasificador. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b8784",
   "metadata": {},
   "source": [
    "### Support vector machine base radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03e677c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.91        67\n",
      "           1       0.90      0.90      0.90        67\n",
      "           2       0.76      0.88      0.82        68\n",
      "           3       0.75      0.71      0.73        66\n",
      "           4       0.87      0.93      0.90        67\n",
      "           5       0.81      0.75      0.78        69\n",
      "\n",
      "    accuracy                           0.84       404\n",
      "   macro avg       0.84      0.84      0.84       404\n",
      "weighted avg       0.84      0.84      0.84       404\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87        67\n",
      "           1       0.86      0.88      0.87        67\n",
      "           2       0.75      0.85      0.80        67\n",
      "           3       0.75      0.61      0.67        67\n",
      "           4       0.84      0.84      0.84        67\n",
      "           5       0.76      0.81      0.79        68\n",
      "\n",
      "    accuracy                           0.81       403\n",
      "   macro avg       0.81      0.81      0.80       403\n",
      "weighted avg       0.81      0.81      0.80       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83        67\n",
      "           1       0.81      0.70      0.75        67\n",
      "           2       0.76      0.85      0.80        67\n",
      "           3       0.74      0.64      0.69        67\n",
      "           4       0.86      0.91      0.88        67\n",
      "           5       0.67      0.81      0.73        68\n",
      "\n",
      "    accuracy                           0.78       403\n",
      "   macro avg       0.79      0.78      0.78       403\n",
      "weighted avg       0.79      0.78      0.78       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        67\n",
      "           1       0.84      0.78      0.81        67\n",
      "           2       0.86      0.90      0.88        67\n",
      "           3       0.76      0.70      0.73        67\n",
      "           4       0.94      0.93      0.93        67\n",
      "           5       0.74      0.81      0.77        68\n",
      "\n",
      "    accuracy                           0.83       403\n",
      "   macro avg       0.83      0.83      0.83       403\n",
      "weighted avg       0.83      0.83      0.83       403\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        67\n",
      "           1       0.90      0.85      0.88        67\n",
      "           2       0.76      0.90      0.82        67\n",
      "           3       0.81      0.64      0.72        67\n",
      "           4       0.90      0.92      0.91        66\n",
      "           5       0.75      0.84      0.79        69\n",
      "\n",
      "    accuracy                           0.84       403\n",
      "   macro avg       0.84      0.84      0.84       403\n",
      "weighted avg       0.84      0.84      0.84       403\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      0       | 0.9047619047619048 | 0.8507462686567164 | 0.8769230769230769 |  335.0  |\n",
      "|      1       | 0.8620689655172413 | 0.8208955223880597 | 0.8409785932721713 |  335.0  |\n",
      "|      2       | 0.7757255936675461 |       0.875        | 0.8223776223776224 |  336.0  |\n",
      "|      3       | 0.7594501718213058 | 0.6616766467065869 |       0.7072       |  334.0  |\n",
      "|      4       | 0.880466472303207  | 0.9041916167664671 | 0.8921713441654356 |  334.0  |\n",
      "|      5       | 0.7452574525745257 | 0.804093567251462  | 0.7735583684950773 |  342.0  |\n",
      "|  macro avg   | 0.8212884267742885 | 0.8194339369615485 | 0.8188681675388972 |  2016.0 |\n",
      "| weighted avg | 0.8210031492727601 | 0.8194444444444444 | 0.8187316129022129 |  2016.0 |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.8194444444444444\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(all_features_standard,all_labels_encoded,5,\"rbf\",True, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55bac21",
   "metadata": {},
   "source": [
    "Se puede observar que un clasificador de SVM con base radial mejora la exactitud del clasificador por casi $17\\%$ lo cual es bastante. Una exactitud de $0.81$ es buena, sin embargo se podría mejorar. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299ec49",
   "metadata": {},
   "source": [
    "## Perceptrón multicapa\n",
    "### Red Neuronal sin cross validation ni hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "126d5399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exactitud en conjunto de prueba sin crossvalidation e hiperparámetros óptimos: 0.7846534848213196\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features_standard, all_labels_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo con Dropout\n",
    "clf = Sequential()\n",
    "clf.add(Dense(60, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "clf.add(Dropout(0.3))  # Agregar Dropout con una tasa del 30%\n",
    "clf.add(Dense(60, activation='relu'))\n",
    "clf.add(Dropout(0.3))  # Agregar Dropout con una tasa del 30%\n",
    "clf.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compilar modelo\n",
    "clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar modelo\n",
    "clf.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),verbose=False)\n",
    "\n",
    "# Evaluar modelo\n",
    "test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'\\nExactitud en conjunto de prueba sin crossvalidation e hiperparámetros óptimos: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce499aa9",
   "metadata": {},
   "source": [
    "Una red neuronal sin validación cruzada ni hiperparámetros óptimos tiene peor comportamiento que un clasificador SVM de base radial, por $3\\%$, un porcentaje menor pero significativo para un clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56987164",
   "metadata": {},
   "source": [
    "### Red Neuronal con cross validation e hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f1a51d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características y etiquetas\n",
    "X = all_features_standard\n",
    "y = all_labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76940b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_tuning_dir\\my_project\\tuner0.json\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 0.1371 - accuracy: 0.9504\n",
      "13/13 [==============================] - 0s 2ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Agua       0.99      0.99      0.99        67\n",
      "      Bosque       0.96      0.97      0.96        67\n",
      "      Ciudad       0.94      0.97      0.96        67\n",
      "     Cultivo       0.84      0.96      0.90        67\n",
      "    Desierto       1.00      0.89      0.94        66\n",
      "     Montaña       1.00      0.93      0.96        69\n",
      "\n",
      "    accuracy                           0.95       403\n",
      "   macro avg       0.95      0.95      0.95       403\n",
      "weighted avg       0.95      0.95      0.95       403\n",
      "\n",
      "Accuracy on test data with cross-validation: 0.9503722190856934\n"
     ]
    }
   ],
   "source": [
    "# Función para crear el modelo \n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=64, max_value=256, step=32), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "    \n",
    "    for i in range(hp.Int('hidden_layers', min_value=1, max_value=10)):\n",
    "        model.add(Dense(units=hp.Int(f'units_{i+2}', min_value=64, max_value=256, step=32), activation='relu'))\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i+2}', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Configurar el sintonizador (RandomSearch en este caso)\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=7,  # Número de combinaciones de hiperparámetros a probar\n",
    "    directory='my_tuning_dir',  # Carpeta para guardar los resultados del sintonizador\n",
    "    project_name='my_project'\n",
    ")\n",
    "\n",
    "# Iterar sobre los pliegues de la validación cruzada\n",
    "for train_index, test_index in cv.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Ejecutar la búsqueda de hiperparámetros en este pliegue\n",
    "    tuner.search(X_train, y_train, epochs=200, batch_size=5, validation_data=(X_test, y_test), verbose = False)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predecir las clases\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calcular el informe de clasificación\n",
    "class_names = label_encoder.classes_\n",
    "classification_rep = classification_report(np.argmax(y_test, axis=1), y_pred_classes, target_names=class_names)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Mostrar la precisión general y la precisión por clase\n",
    "print(f'Accuracy on test data with cross-validation: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6211409b",
   "metadata": {},
   "source": [
    "Una red neuronal con hiperparámetros óptimos y validación cruzada mejora por mucho al momento de clasificar imágenes satelitales. Su exactitud es de $0.95$, supera al SVM base radial por $14\\%$. Una exactitud de $95\\%$ es excelente para un clasificador y es un modelo que sin duda se puede utilizar para seguir clasificando biomasas de México con fotos satelitales. Se comprueba nuevamente que una red neuronal es mucho mejor que cualquier clasificador clásico. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94f7f4c",
   "metadata": {},
   "source": [
    "# Clasificadores de imágenes de verduras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c351545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de características: (2528, 28)\n",
      "Dimensiones de etiquetas: (2528,)\n"
     ]
    }
   ],
   "source": [
    "# Establecer el ancho y altura de las imágenes después del redimensionamiento\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "# Directorio raíz donde se encuentran las carpetas de clases\n",
    "root_dir = \"data_verduras\"\n",
    "\n",
    "# Lista de subdirectorios (cada subdirectorio es una clase)\n",
    "class_folders = [folder for folder in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, folder))]\n",
    "\n",
    "# Listas para almacenar características y etiquetas\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "# Función para extraer características de una imagen\n",
    "def extract_features(image):\n",
    "    # Redimensionar la imagen a 128x128\n",
    "    rgb_resized = resize(image, (img_height, img_width), anti_aliasing=True)\n",
    "\n",
    "    # Convertir a escala de grises\n",
    "    gray_resized = img_as_ubyte(rgb2gray(rgb_resized))\n",
    "\n",
    "    # Histogramas de color\n",
    "    nbins = 8\n",
    "    rh = np.histogram(rgb_resized[:,:,0].flatten(), nbins, density=True)\n",
    "    gh = np.histogram(rgb_resized[:,:,1].flatten(), nbins, density=True)\n",
    "    bh = np.histogram(rgb_resized[:,:,2].flatten(), nbins, density=True)\n",
    "    hist_descriptor = np.concatenate((rh[0], gh[0], bh[0]))\n",
    "\n",
    "    # Descriptores de textura usando GLCM\n",
    "    glcm = graycomatrix(gray_resized, distances=[5], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4])\n",
    "    texture_desc = [graycoprops(glcm, 'dissimilarity')[0, 0], graycoprops(glcm, 'homogeneity')[0, 0], graycoprops(glcm, 'energy')[0, 0], graycoprops(glcm, 'correlation')[0, 0]]\n",
    "\n",
    "    return hist_descriptor, texture_desc\n",
    "\n",
    "# Iterar sobre cada carpeta de clase\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(root_dir, class_folder)\n",
    "\n",
    "    # Iterar sobre cada archivo de imagen en la carpeta de clase\n",
    "    for filename in os.listdir(class_path):\n",
    "        if filename.endswith(('.jpg', '.png', '.jpeg')):  # Asegurarse de que el archivo sea una imagen\n",
    "            image_path = os.path.join(class_path, filename)\n",
    "\n",
    "            # Cargar la imagen\n",
    "            rgb = io.imread(image_path)\n",
    "\n",
    "            # Extraer características\n",
    "            hist_descriptor, texture_desc = extract_features(rgb)\n",
    "\n",
    "            # Almacenar características y etiquetas\n",
    "            all_features.append(np.concatenate([hist_descriptor, texture_desc]))\n",
    "            all_labels.append(class_folder)\n",
    "\n",
    "# Convertir a matrices numpy\n",
    "all_features = np.array(all_features)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Verificar las dimensiones de las matrices resultantes\n",
    "print(\"Dimensiones de características:\", all_features.shape)\n",
    "print(\"Dimensiones de etiquetas:\", all_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0a52297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.47700384,  2.41829852,  4.06007916,  0.59680945,  0.04880969,\n",
       "        0.05546556,  0.49475282,  0.93625869,  0.7017579 ,  3.08305636,\n",
       "        4.13101482,  0.0654974 ,  0.05146225,  0.09590691,  0.64561727,\n",
       "        0.80702158,  0.51769923,  2.41592974,  4.06366062,  2.50499627,\n",
       "        0.08906653,  0.31173287,  0.96581523,  0.53161587, 16.91075212,\n",
       "        0.13365381,  0.02664937,  0.78494875])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae4a2191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cebolla'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "011f8c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar las características\n",
    "all_features_standard = (all_features - all_features.min()) / (all_features.max() - all_features.min())\n",
    "\n",
    "# Codificar etiquetas\n",
    "label_encoder = LabelEncoder()\n",
    "all_labels_encoded = label_encoder.fit_transform(all_labels)\n",
    "\n",
    "# Codificar etiquetas en formato one-hot\n",
    "all_labels_onehot = to_categorical(all_labels_encoded, num_classes=len(label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96460628",
   "metadata": {},
   "source": [
    "## Suport Vector Machine base lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f99d2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       101\n",
      "           1       0.93      0.85      0.89       100\n",
      "           2       0.91      0.96      0.94       105\n",
      "           3       0.85      0.87      0.86       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.94       506\n",
      "   macro avg       0.94      0.94      0.94       506\n",
      "weighted avg       0.94      0.94      0.94       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       0.94      0.89      0.91       101\n",
      "           2       0.93      1.00      0.96       105\n",
      "           3       0.93      0.92      0.92       100\n",
      "           4       1.00      0.98      0.99       100\n",
      "\n",
      "    accuracy                           0.96       506\n",
      "   macro avg       0.96      0.96      0.96       506\n",
      "weighted avg       0.96      0.96      0.96       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       100\n",
      "           1       0.96      0.90      0.93       101\n",
      "           2       0.94      0.99      0.96       105\n",
      "           3       0.92      0.94      0.93       100\n",
      "           4       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.96       506\n",
      "   macro avg       0.96      0.96      0.96       506\n",
      "weighted avg       0.96      0.96      0.96       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       0.98      0.88      0.93       101\n",
      "           2       0.92      0.98      0.95       104\n",
      "           3       0.94      0.97      0.96       100\n",
      "           4       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.96       505\n",
      "   macro avg       0.97      0.96      0.96       505\n",
      "weighted avg       0.97      0.96      0.96       505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       100\n",
      "           1       0.99      0.87      0.93       100\n",
      "           2       0.97      0.99      0.98       105\n",
      "           3       0.89      0.97      0.93       100\n",
      "           4       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.96       505\n",
      "   macro avg       0.96      0.96      0.96       505\n",
      "weighted avg       0.96      0.96      0.96       505\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      0       | 0.9900793650793651 | 0.9960079840319361 | 0.9930348258706468 |  501.0  |\n",
      "|      1       | 0.9587852494577006 | 0.878727634194831  | 0.9170124481327802 |  503.0  |\n",
      "|      2       | 0.9330922242314648 | 0.9847328244274809 | 0.9582172701949861 |  524.0  |\n",
      "|      3       | 0.9067961165048544 |       0.934        | 0.9201970443349754 |  500.0  |\n",
      "|      4       |        1.0         |        0.99        | 0.9949748743718593 |  500.0  |\n",
      "|  macro avg   | 0.9577505910546769 | 0.9566936885308497 | 0.9566872925810497 |  2528.0 |\n",
      "| weighted avg | 0.9575305087546281 | 0.9568829113924051 | 0.956669113175464  |  2528.0 |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.9568829113924051\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(all_features_standard,all_labels_encoded,5,\"linear\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f204c6",
   "metadata": {},
   "source": [
    "## Support Vector Machine base radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "937a645e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       101\n",
      "           1       1.00      0.98      0.99       100\n",
      "           2       1.00      1.00      1.00       105\n",
      "           3       0.97      1.00      0.99       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.99       506\n",
      "   macro avg       0.99      0.99      0.99       506\n",
      "weighted avg       0.99      0.99      0.99       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       0.99      0.94      0.96       101\n",
      "           2       1.00      1.00      1.00       105\n",
      "           3       0.94      0.98      0.96       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.98       506\n",
      "   macro avg       0.98      0.98      0.98       506\n",
      "weighted avg       0.98      0.98      0.98       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       1.00      0.98      0.99       101\n",
      "           2       1.00      1.00      1.00       105\n",
      "           3       0.98      1.00      0.99       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           1.00       506\n",
      "   macro avg       1.00      1.00      1.00       506\n",
      "weighted avg       1.00      1.00      1.00       506\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       0.97      0.98      0.98       101\n",
      "           2       1.00      1.00      1.00       104\n",
      "           3       0.98      0.96      0.97       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.99       505\n",
      "   macro avg       0.99      0.99      0.99       505\n",
      "weighted avg       0.99      0.99      0.99       505\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       100\n",
      "           1       0.99      0.95      0.97       100\n",
      "           2       1.00      1.00      1.00       105\n",
      "           3       0.95      0.99      0.97       100\n",
      "           4       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.99       505\n",
      "   macro avg       0.99      0.99      0.99       505\n",
      "weighted avg       0.99      0.99      0.99       505\n",
      "\n",
      "Resultados del clasificador:\n",
      "\n",
      "\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|    Clase     |     Precisión      |       Recall       |     Puntaje F1     | Soporte |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "|      0       | 0.9960159362549801 | 0.998003992015968  | 0.9970089730807578 |  501.0  |\n",
      "|      1       | 0.9898167006109979 | 0.9662027833001988 | 0.9778672032193158 |  503.0  |\n",
      "|      2       |        1.0         |        1.0         |        1.0         |  524.0  |\n",
      "|      3       | 0.9647749510763209 |       0.986        | 0.9752720079129575 |  500.0  |\n",
      "|      4       |        1.0         |        1.0         |        1.0         |  500.0  |\n",
      "|  macro avg   | 0.9901215175884598 | 0.9900413550632333 | 0.9900296368426063 |  2528.0 |\n",
      "| weighted avg | 0.9902172705732745 | 0.9901107594936709 | 0.9901126197346735 |  2528.0 |\n",
      "+--------------+--------------------+--------------------+--------------------+---------+\n",
      "\n",
      "Accuracy =  0.9901107594936709\n"
     ]
    }
   ],
   "source": [
    "SVM_cross_validation(all_features_standard,all_labels_encoded,5,\"rbf\",True, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384a3736",
   "metadata": {},
   "source": [
    "## Perceptron multicapa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06b0bee",
   "metadata": {},
   "source": [
    "### Red Neuronal sin cross validation ni hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f20d3fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exactitud en conjunto de prueba sin crossvalidation e hiperparámetros óptimos: 0.9960474371910095\n"
     ]
    }
   ],
   "source": [
    "# Dividir datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features_standard, all_labels_onehot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo con Dropout\n",
    "clf = Sequential()\n",
    "clf.add(Dense(60, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "clf.add(Dropout(0.3))  # Agregar Dropout con una tasa del 30%\n",
    "clf.add(Dense(60, activation='relu'))\n",
    "clf.add(Dropout(0.3))  # Agregar Dropout con una tasa del 30%\n",
    "clf.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compilar modelo\n",
    "clf.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Ajustar modelo\n",
    "clf.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test),verbose=False)\n",
    "\n",
    "# Evaluar modelo\n",
    "test_loss, test_acc = clf.evaluate(X_test, y_test, verbose=False)\n",
    "print(f'\\nExactitud en conjunto de prueba sin crossvalidation e hiperparámetros óptimos: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6decd9c",
   "metadata": {},
   "source": [
    "### Red Neuronal con cross validation y hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8758f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en características y etiquetas\n",
    "X = all_features_standard\n",
    "y = all_labels_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bdaf5815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9941\n",
      "16/16 [==============================] - 0s 3ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Cebolla       1.00      1.00      1.00       100\n",
      "     Chayote       1.00      0.97      0.98       100\n",
      "    Jitomate       1.00      1.00      1.00       105\n",
      "      Pepino       0.97      1.00      0.99       100\n",
      "   Zanahoria       1.00      1.00      1.00       100\n",
      "\n",
      "    accuracy                           0.99       505\n",
      "   macro avg       0.99      0.99      0.99       505\n",
      "weighted avg       0.99      0.99      0.99       505\n",
      "\n",
      "Accuracy on test data with cross-validation: 0.9940593838691711\n"
     ]
    }
   ],
   "source": [
    "# Función para crear el modelo \n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=64, max_value=256, step=32), activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "    \n",
    "    for i in range(hp.Int('hidden_layers', min_value=1, max_value=10)):\n",
    "        model.add(Dense(units=hp.Int(f'units_{i+2}', min_value=64, max_value=256, step=32), activation='relu'))\n",
    "        model.add(Dropout(hp.Float(f'dropout_{i+2}', min_value=0.2, max_value=0.7, step=0.1)))\n",
    "\n",
    "    model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Configurar la validación cruzada\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Configurar el sintonizador (RandomSearch en este caso)\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=7,  # Número de combinaciones de hiperparámetros a probar\n",
    "    directory='my_tuning_dir1',  # Carpeta para guardar los resultados del sintonizador\n",
    "    project_name='my_project1'\n",
    ")\n",
    "\n",
    "# Iterar sobre los pliegues de la validación cruzada\n",
    "for train_index, test_index in cv.split(X, np.argmax(y, axis=1)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Ejecutar la búsqueda de hiperparámetros en este pliegue\n",
    "    tuner.search(X_train, y_train, epochs=100, batch_size=5, validation_data=(X_test, y_test), verbose = False)\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba\n",
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Predecir las clases\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Calcular el informe de clasificación\n",
    "class_names = label_encoder.classes_\n",
    "classification_rep = classification_report(np.argmax(y_test, axis=1), y_pred_classes, target_names=class_names)\n",
    "\n",
    "# Mostrar el informe de clasificación\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Mostrar la precisión general y la precisión por clase\n",
    "print(f'Accuracy on test data with cross-validation: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb697f37",
   "metadata": {},
   "source": [
    "Por la naturaleza del conjunto de imágenes tanto los clasificadores SVM como el perceptrón tuvieron un excelente comportamiento. Pero el mejor modelo dentro de todo es la red neuronal con una exactitud de $99.41\\%$, lo cual es asombroso. Se podría pensar que el modela esta sobreajustando, pero las excelentes clasificaciones se deben a un buen conjunto de imágenes. Este último conjunto de imágenes, comprueban nuevamente que para clasificar imágenes el mejor clasificador es el perceptrón multicapa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
